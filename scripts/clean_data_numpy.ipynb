{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "#from implementations import *\n",
    "from Leo import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost  15.245600000000003  % of your data by removing  38114  rows\n",
      "Lost  8.554128163257602  % of your data by detecting  18125  outliers\n",
      "file_written\n"
     ]
    }
   ],
   "source": [
    "#print(tX[:,22])\n",
    "# found that the jet number is in column 22\n",
    "\n",
    "# isolate the jet numbers and remove jet number column:\n",
    "x_j0 = tX[np.where(tX[:, 22] == 0)]\n",
    "x_j0 = np.hstack((x_j0[:,:22], x_j0[:,23:]))\n",
    "\n",
    "x_j1 = tX[np.where(tX[:, 22] == 1)]\n",
    "x_j1 = np.hstack((x_j1[:,:22], x_j1[:,23:]))\n",
    "\n",
    "x_j2 = tX[np.where(tX[:, 22] == 2)]\n",
    "x_j2 = np.hstack((x_j2[:,:22], x_j2[:,23:]))\n",
    "\n",
    "x_j3 = tX[np.where(tX[:, 22] == 3)]\n",
    "x_j3 = np.hstack((x_j3[:,:22], x_j3[:,23:]))\n",
    "\n",
    "# remove the jet column from the original data set\n",
    "tX_no_jet = np.hstack((tX[:,:22], tX[:,23:]))\n",
    "\n",
    "# append the y and ids columns such that they are treated as well\n",
    "N = len(y)\n",
    "tX_full = np.hstack((tX_no_jet, np.reshape(y, (N, 1)), np.reshape(ids, (N, 1))))\n",
    "\n",
    "def column_remover_999(x, verbose = True):\n",
    "    col_num_initial = len(x[0,:])\n",
    "    x = x.transpose()\n",
    "    lost_cols = np.where(np.all(x == -999, 1))[0]\n",
    "    x = x[np.where(np.any(x != -999, 1))]\n",
    "    x = x.transpose()\n",
    "    if verbose:\n",
    "        print(\"Lost \", col_num_initial - len(x[0,:]), \" columns. The lost columns are: \", lost_cols)\n",
    "    \n",
    "    return x\n",
    "\n",
    "x_j0 = column_remover_999(x_j0, verbose = False) # loses 10 columns:  4  5  6 12 22 23 24 25 26 27\n",
    "x_j1 = column_remover_999(x_j1, verbose = False) # loses 7 columns:  4  5  6 12 25 26 27\n",
    "x_j2 = column_remover_999(x_j2, verbose = False) # loses no columns\n",
    "x_j3 = column_remover_999(x_j3, verbose = False) # loses no columns\n",
    "\n",
    "def row_cleaner_999(x, verbose = True):\n",
    "    len_initial = len(x)\n",
    "    x = x[np.where(np.all(x != -999, 1))]\n",
    "    if verbose:\n",
    "        print(\"Lost \", 100 * (1 - len(x) / len_initial), \" % of your data by removing \", len_initial - len(x), \" rows\")\n",
    "    \n",
    "    return x\n",
    "\n",
    "x_j0 = cleaner_999(x_j0, verbose = False) # loses 26.1 % of data\n",
    "x_j1 = cleaner_999(x_j1, verbose = False) # loses 9.8 % of data\n",
    "x_j2 = cleaner_999(x_j2, verbose = False) # loses 5.6 % of data\n",
    "x_j3 = cleaner_999(x_j3, verbose = False) # loses 6.7 % of data\n",
    "\n",
    "def clean_999(x, verbose = True):\n",
    "    #bad_col_set = [ 4,  5,  6, 12, 22, 23, 24, 25, 26, 27]\n",
    "    x = np.hstack((x[:,:4], x[:,7:12], x[:,13:22], x[:,28:]))\n",
    "    x = row_cleaner_999(x, verbose)\n",
    "    return x\n",
    "\n",
    "tX_no_999 = clean_999(tX_full) # Loses a total of 15.2% of the data\n",
    "\n",
    "# Note: discuss the extent to which it makes sense to discuss outliers for a classification problem\n",
    "def remove_outliers_kIQR(x, k = 3, verbose = True):\n",
    "    len_initial = len(x)\n",
    "    Q1, Q3 = np.quantile(x, [0.25, 0.75], 0)\n",
    "    IQR = Q3 - Q1\n",
    "    x = x[np.where((np.all(x > Q1 - k * IQR, 1)) & (np.all(x < Q3 + k * IQR, 1)))] # Tukey's Fence to filter points that are \"far out\"\n",
    "    len_new = len(x)\n",
    "    if verbose:\n",
    "        print(\"Lost \", 100 * (1 - len_new / len_initial), \" % of your data by detecting \", len_initial - len_new, \" outliers\")\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "tX_clean = remove_outliers_kIQR(tX_no_999, 3)\n",
    "\n",
    "new_tX, new_y, new_ids = tX_clean[:, :-2], tX_clean[:, -2], tX_clean[:, -1]\n",
    "\n",
    "\n",
    "# Store tX, with y in the second last column and the ids in the last column\n",
    "with open('Leo_clean_dat.txt', 'w') as f:\n",
    "    for row in tX_clean:\n",
    "        for item in row:\n",
    "            f.write(\"%s,\" % item)\n",
    "        f.write(\"\\n\")\n",
    "    print(\"file_written\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "[-1.69943214e+91 -9.09508239e+90 -1.36319924e+91 -2.29124144e+90\n",
      " -3.72433326e+89 -1.01991642e+90 -1.22164072e+91 -2.34751146e+89\n",
      "  1.39060725e+89 -2.67055703e+90 -3.30423210e+88 -1.52731033e+89\n",
      " -6.37407764e+90  1.80761260e+89  1.52138559e+89 -3.63070949e+90\n",
      " -2.22163469e+89 -2.93795541e+91 -3.17177252e+90]\n",
      "7.5562744411050735e+177\n"
     ]
    }
   ],
   "source": [
    "w0 = np.ones(np.shape(new_tX)[1])*0\n",
    "print(\"hi\")\n",
    "w, loss = least_squares_SGD(new_y, new_tX, w0, 20, 0.8)\n",
    "print(w)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine-learning-higgs/scripts/implementations.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(tx,y)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "[ 8.03494351e-05 -7.20202266e-03 -6.05417274e-03 -5.47559078e-04\n",
      " -1.93874687e-02  4.73451612e-04 -2.60379058e-02  3.25106299e-01\n",
      " -3.80780004e-05 -2.72787427e+00 -2.21220141e-01  9.50794097e-02\n",
      "  6.40351607e-02  2.73613395e+00 -3.31801099e-04 -9.54325141e-04\n",
      "  2.74089070e+00 -5.34165277e-04  9.73498906e-04  3.69225050e-03\n",
      "  3.54487171e-04 -5.43344618e-04 -3.30448035e-01 -1.40800497e-03\n",
      "  8.31432843e-04  1.02117275e-03 -1.68047418e-03 -5.83664781e-03\n",
      " -1.11088003e-02  2.72833421e+00]\n",
      "0.3396868094770344\n"
     ]
    }
   ],
   "source": [
    "w, loss = least_squares(y, tX)\n",
    "print(shape(tX))\n",
    "print(w)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": " not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_86/2767638011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATA_TEST_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;31m# TODO: download train data and supply path here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_TEST_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/machine-learning-higgs/scripts/proj1_helpers.py\u001b[0m in \u001b[0;36mload_csv_data\u001b[0;34m(data_path, sub_sample)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_csv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m:  not found."
     ]
    }
   ],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
